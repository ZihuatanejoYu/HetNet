<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Project website of the paper Noise Fusion-based Distillation Learning for Anomaly Detection in Complex Industrial Environments">
  <meta name="keywords" content="anomaly detection, knowledge distillation, complex industrial environments, heterogeneous feature fusion">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Noise Fusion-based Distillation Learning for Anomaly Detection in Complex Industrial Environments</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Noise Fusion-based Distillation Learning for Anomaly Detection in Complex Industrial Environments</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <span>Jiawen Yu</span><sup>1</sup>,
            </span>
            <span class="author-block">
              <span>Jieji Ren</span><sup>2</sup>,
            </span>
            <span class="author-block">
              <span>Yang Chang</span><sup>1</sup>,
            </span>
            <span class="author-block">
              <span>Qiaojun Yu</span><sup>2</sup>,
            </span>
            <span class="author-block">
              <span>Xuan Tong</span><sup>1</sup>,
            </span>
            <span class="author-block">
              <span>Boyang Wang</span><sup>1</sup>,
            </span>
            <span class="author-block">
              <span>Yan Song</span><sup>1</sup>
            </span>
            <span class="author-block">
              <span>You Li</span><sup>1</sup>
            </span>
            <span class="author-block">
              <span>Xinji Mai</span><sup>1</sup>
            </span>
            <span class="author-block">
              <span>Wenqiang Zhang</span><sup>3*</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Shanghai Engineering Research Center of AI & Robotics, Academy for Engineering & Technology, Fudan University, Shanghai, China,</span>
            <span class="author-block"><sup>2</sup>Shanghai Jiao Tong University, Shanghai, China</span>
            <span class="author-block"><sup>3</sup>Engineering Research Center of AI & Robotics,
              Ministry of Education, Academy for Engineering & Technology, Fudan
              University, Shanghai, China</span>
            


          </div>


          <!-- ###################待改#################### -->
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/E-hYn9_H8Jo"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ZihuatanejoYu/HetNet"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section> -->


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/E-hYn9_H8Jo?si=DPjlglSexTeZOrf0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
      </div>
    </div>

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Anomaly detection and localization in automated
            industrial manufacturing can significantly enhance production
            efficiency and product quality. Existing methods are capable of detecting surface defects in pre-defined or controlled
            imaging environments. However, accurately detecting workpiece
            defects in complex and unstructured industrial environments
            with varying views, poses and illumination remains challenging. We propose a novel anomaly detection and localization
            method specifically designed to handle inputs with perturbative
            patterns. Our approach introduces a new framework based
            on a collaborative distillation heterogeneous teacher network
            (HetNet), an adaptive local-global feature fusion module, and
            a local multivariate Gaussian noise generation module. HetNet
            can learn to model the complex feature distribution of normal patterns using limited information about local disruptive
            changes. We conducted extensive experiments on mainstream
            benchmarks. HetNet demonstrates superior performance with approximately 10% improvement across all evaluation metrics
            on MSC-AD under industrial conditions, while achieving stateof-the-art results on other datasets, validating its resilience to
            environmental fluctuations and its capability to enhance the
            reliability of industrial anomaly detection systems across diverse
            scenarios. Tests in real-world environments further confirm
            that HetNet can be effectively integrated into production lines
            to achieve robust and real-time anomaly detection.
            
          </p>
          <!-- <a href="https://zihuatanejoyu.github.io/HetNet/">https://zihuatanejoyu.github.io/HetNet/</a> -->
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    
    <!--/ Paper video. -->
  </div>
</section>

<section class="section">
  <div class="a">

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <img src="./static/images/teaser.png" width="800px" class="rounded">
      </div>
    </div>

    
    <!-- Introduction. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p>
            In modern manufacturing environments, surface defect 
            detection is crucial for ensuring product quality and 
            structural integrity. As flexible manufacturing systems 
            evolve, traditional fixed-position inspection stations 
            have become inadequate, while robot-based inspection 
            systems introduce new challenges despite their flexibility. 
            HetNet is an innovative unsupervised anomaly detection 
            framework designed to overcome key limitations in 
            robot-based inspection by addressing real production 
            environment challenges including uncontrolled 
            illumination conditions, perspective variations, 
            and magnification differences. Through multi-modal 
            feature extraction mechanisms, HetNet more effectively 
            characterizes the probabilistic distribution of normal 
            patterns, integrating CNN and Transformer networks to 
            simultaneously capture heterogeneous features and 
            local-global contextual information. The framework 
            employs an adaptive local-global feature fusion 
            module that optimizes information flow between 
            complementary feature spaces, implements a 
            collaborative distillation framework executing 
            joint optimization objectives including reconstruction 
            and denoising tasks, and introduces a local multivariate 
            Gaussian noise generation module that effectively expands 
            the decision boundary. HetNet provides a robust solution 
            for industrial automated inspection systems, particularly 
            suitable for automotive, aerospace, and precision machinery 
            sectors where high accuracy and reliability are required.
            
          </p>
          <!-- <a href="https://zihuatanejoyu.github.io/HetNet/">https://zihuatanejoyu.github.io/HetNet/</a> -->
        </div>
      </div>
    </div>
    <!--/ Introduction. -->

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <img src="./static/images/pipeline.png" width="800px" class="rounded">
      </div>
    </div>

    <!-- Pipeline. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Pipeline</h2>
        <div class="content has-text-justified">
          <p>
            Our pipeline consists of four modules. 
            The image is input into two heterogeneous 
            encoders to obtain local and global representations. 
            The hybrid feature fusion strategy consists of the ALGF 
            module and the MHF module. ALGF fuses heterogeneous features,
             facilitating effective interaction between global and local 
             characteristics, and the MHF module combines features from
              different layers. The collaborative student distills
               knowledge from the teachers by noise fusion-based
                distillation learning. The noise for denoising is
                 generated by the LMGN generator. Please check our
                  main paper for more technical details.
            
          </p>
          <!-- <a href="https://zihuatanejoyu.github.io/HetNet/">https://zihuatanejoyu.github.io/HetNet/</a> -->
        </div>
      </div>
    </div>
    <!--/ Pipeline. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <img src="./static/images/quality_result.png" width="800px" class="rounded">
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <img src="./static/images/quantity_result.png" width="800px" class="rounded">
      </div>
    </div>
    <!-- Experiments. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Experiments</h2>
        <div class="content has-text-justified">
          <p>
            We validated our method on the MSC-AD dataset, 
            a challenging benchmark for industrial anomaly detection. 
            HetNet outperforms SOTA methods in all categories, 
            improving image-level AUROC by 18.46% over the second-best 
            method and nearly 40% over others. From left to right, 
            we present anomaly localization results for samples under 
            varying illumination, resolution, and positioning conditions. 
            Predictions made by HetNet robustly adapt to input 
            disturbances and exhibit more stable performance across 
            diverse environmental conditions. We conducted ablation 
            experiments to exhibit the effectiveness of each module 
            in HetNet. Additional tests on the MVTec-AD, VisA and MPDD 
            datasets confirmed its generalization ability and robustness.
            
          </p>
          <!-- <a href="https://zihuatanejoyu.github.io/HetNet/">https://zihuatanejoyu.github.io/HetNet/</a> -->
        </div>
      </div>
    </div>
    <!--/ Experiments. -->

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <img src="./static/images/ablations.png" width="800px" class="rounded">
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <img src="./static/images/result2.png" width="350px" class="rounded">
      </div>
    </div>
    The extra qualitative comparisons demonstrates HetNet's effectiveness in reducing false positives on normal disruptive patterns. 

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <img src="./static/images/real_world.png" width="350px" class="rounded">
      </div>
    </div>
    We deployed HetNet in a real-world inspection setting to detect surface defects on precision metal components.
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <!-- <h2 class="title is-3">Visual Effects</h2>
          <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p> -->
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/final_real_circle.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      

      <div class="column">
        <!-- <h2 class="title is-3">Matting</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              As a byproduct of our method, we can also solve the matting problem by ignoring
              samples that fall outside of a bounding box during rendering.
            </p> -->
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/final_real_long.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div> 
      <!--/ Matting.

    


    

  </div>
</section>


<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section> -->


<!-- 这里的源码链接记得改 -->
<!-- <footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer> -->

</body>
</html>
